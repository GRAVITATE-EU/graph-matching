# !/usr/bin/env python
# -*- coding: utf-8 -*-

"""
..
	/////////////////////////////////////////////////////////////////////////
	//
	// (c) Copyright University of Southampton IT Innovation, 2015
	//
	// Copyright in this software belongs to IT Innovation Centre of
	// Gamma House, Enterprise Road, Southampton SO16 7NS, UK.
	//
	// This software may not be used, sold, licensed, transferred, copied
	// or reproduced in whole or in part in any manner or form or in or
	// on any media by any person other than in accordance with the terms
	// of the Licence Agreement supplied with the software, or otherwise
	// without the prior written consent of the copyright owners.
	//
	// This software is distributed WITHOUT ANY WARRANTY, without even the
	// implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
	// PURPOSE, except where stated in the Licence Agreement supplied with
	// the software.
	//
	// Created By : jessica Rosati
	// Created Date : 2017/06/27
	// Created for Project : GRAVITATE
	//
	/////////////////////////////////////////////////////////////////////////
	//
	// Dependencies : NONE
	//
	/////////////////////////////////////////////////////////////////////////
	'''

This module reads a file with distances between artefacts and evaluates precision.
Precision is defined as the ratio between the number of true positive (TP) and the value of yield (TP + FP).
"""

import operator, logging, codecs
import ConfigParser
from rdf_walks2vec_app import ConfigSectionReader
import random


def read_file_with_distances( file_with_distances,logger ):
	"""Reads the file with the distances.

	This function reads the file with the distances generated by an app
	and builds dict_with_distances with entries <(artefact1, artefact2), distance>
	:param file_with_distances: the path of the file with distances (each line in the file is made of artefact1 \t artefact2 \t distance)
	:type file_with_distances: String
	:return: list [ (artefact1, artefact2), distance ] sorted by distance
	:rtype: list
	"""
	list_result = []
	readHandle = codecs.open( file_with_distances, 'r', 'utf-8', errors = 'replace' )
	content = readHandle.readlines()
	for line in content:
		line_splitted = line.rstrip('\n\r').split("\t")
		if len(line_splitted) == 3 :
			artefact1=line_splitted[0]
			artefact2=line_splitted[1]
			distance=float( line_splitted[2] )
			if (not 'ged_filter_zero_distances' in ConfigSectionReader(Config,"ged_app")) or (ConfigSectionReader(Config,"ged_app")['ged_filter_zero_distances'] == 'False') :
				#list_result.append( [ (artefact1, artefact2), distance + 0.000001 * random.randint( 0,1000 ) ] )
				list_result.append( [ (artefact1, artefact2), distance ] )
			else :
				# for GED a score of 0.0 appears to be a default no GED (i.e. completely different graph)
				# overall low score is good, so 0.0 is worse than everything. 1.0 is better than 2.0, which is better than 7.0 etc.
				if distance > 0.0 :
					# list_result.append( [ (artefact1, artefact2), distance + 0.000001 * random.randint( 0,1000 ) ] )
					list_result.append( [ (artefact1, artefact2), distance ] )
	readHandle.close()

	# remove any duplicate or mirrored artifact pairs
	logger.info( 'removing duplicate and mirrored pairs' )
	nMirror = 0
	nDuplicate = 0
	nIndex1 = 0
	while nIndex1 < len(list_result) :
		nIndex2 = nIndex1 + 1
		while nIndex2 < len(list_result) :

			bBad = False
			# check duplicate
			if list_result[nIndex1][0] == list_result[nIndex2][0] :
				nDuplicate = nDuplicate + 1
				bBad = True
			# check mirror
			if list_result[nIndex1][0] == ( list_result[nIndex2][0][1], list_result[nIndex2][0][0] ) :
				nMirror = nMirror + 1
				bBad = True
			
			if bBad == True :
				del list_result[nIndex2]
			else :
				nIndex2 = nIndex2 + 1

		nIndex1 = nIndex1 + 1
	logger.info( 'mirrored (' + str(nMirror) + ') duplicates (' + str(nDuplicate) + ')' )

	# sort, using small fraction random noise to split up randomly scores with same distance value
	logger.info( 'sorting pairs by score' )
	list_result = sorted( list_result, key=lambda entry: entry[1], reverse = False )

	# return sorted list
	return list_result

def read_artefacts_and_create_dict_with_clusters(fname_artefacts, fname_clusters, logger):
	"""Reads the file with the artefacts and creates a dictionary.

	This function reads the file with the artefacts and builds:
	the list of all artefacts, i.e., artefacts_all, and
	the list of artefacts whose cluster in known, i.e., artafacts_reduced.
	For artefacts whose cluster in known, a dictonary <artefact, cluster> is created.
	:param fname_artefacts: the path of the file with artafacts (each line in the file corresponds to an artefact)
	:type fname_artefacts: String
	:param fname_clusters: the path of the file with artafacts (each line in the file corresponds to an artefact)
	:type fname_clusters: String
	:param logger
	:return: the dictionary <artefact, cluster>
	:rtype: dict
	"""
	dict_artefact_cluster = {}
	readHandle = codecs.open( fname_artefacts, 'r', 'utf-8', errors = 'replace' )
	content = readHandle.readlines()	
	for line in content:
		line = line.rstrip('\n\r')
		'''
		# REMOVED AS WONT WORK FOR DBPEDIA
		# remove the BM namespace so we are working with just the ID not the URI
		line = line.replace("http://collection.britishmuseum.org/id/object/","")
		line = line.replace("http://o/","")
		'''

		artefacts_all.append(line)
	readHandle.close()

	nClusterIDMax = 0
	readHandle = codecs.open( fname_clusters, 'r', 'utf-8', errors = 'replace' )
	content = readHandle.readlines()
	for line in content:
		line_splitted = line.rstrip('\n\r').split("\t")
		cluster=line_splitted[1]
		if(int(cluster) > 0):
			if not line_splitted[0] in dict_artefact_cluster :
				dict_artefact_cluster[line_splitted[0]] = set([])
			dict_artefact_cluster[line_splitted[0]].add( int(cluster) )
			if int(cluster) > nClusterIDMax :
				nClusterIDMax = int(cluster)
	readHandle.close()

	logger.info( 'number of ground truth clusters = ' + str(nClusterIDMax) )

	return dict_artefact_cluster

def compute_precision_at_yield( Yield,logger ):
	"""Computes precision at a certain yield and writes it.

	This function computes precision (TP/(TP+FP)) at a certain yield, for yield in the list Yield of possible values.
	Precision is written into a file.
	:param Yield: the list of values of yield to consider in the computation of precision@yield
	:type Yield: list
	:param logger
	"""

	precision_scores_file = codecs.open( ConfigSectionReader(Config,"evaluation_app")['precision_scores_file'], 'a', 'utf-8', errors = 'replace' )
	#precision_scores_file = open( ConfigSectionReader(Config,"evaluation_app")['precision_scores_file'], 'a')
	precision_scores_file.write( '#yield, P, yield, P, ...\n' )

	for yield_value in Yield:

		yield_value = int(yield_value)
		logger.info( 'target yield =  ' + repr(yield_value) )

		# get top N scores for this yield
		listScoreSubset = list_scores[ 0:yield_value ]

		dict_true_positive = {}
		nFP = 0
		nTP = 0
		set_artifact_in_yield = set([])
		set_artifact_in_yield_ground_truth = set([])

		for (tuplePair, nScore) in listScoreSubset :

			(first_artifact, second_artifact) = tuplePair

			set_artifact_in_yield.add( first_artifact )
			set_artifact_in_yield.add( second_artifact )

			'''
			# ignore pair if both artifacts are not in the ground truth set
			if (first_artifact not in dict_artefact_cluster) and (second_artifact not in dict_artefact_cluster) :
				if (not (first_artifact, second_artifact) in setTN) and (not (second_artifact, first_artifact) in setTN) :
					setTN.add( (first_artifact, second_artifact) )
				continue

			# keep track of how many ground truth artifacts we have seen in result
			if first_artifact in dict_artefact_cluster :
				set_artifact_in_yield_ground_truth.add( first_artifact )
			if second_artifact in dict_artefact_cluster :
				set_artifact_in_yield_ground_truth.add( second_artifact )
			'''

			# its a FP if one of the pair is not in ground truth set
			if (first_artifact not in dict_artefact_cluster) :
				nFP = nFP + 1
				continue
			if (second_artifact not in dict_artefact_cluster) :
				nFP = nFP + 1
				continue

			# all artifacts are in a ground truth cluster, so now check they share a cluster ID (FP if not)
			# note: record pair not a simple count to avoid mirror pair counting twice
			if len( dict_artefact_cluster[first_artifact].intersection( dict_artefact_cluster[second_artifact] ) ) > 0 :
				nTP = nTP + 1
			else:
				nFP = nFP + 1

		if nTP + nFP > 0 :
			nPrecision = 1.0 * nTP / ( nTP + nFP )
			logger.info( 'precision =  ' + repr( nPrecision ) )
		else :
			nPrecision = 0.0
			logger.info( 'precision = 0.0' )

		#logger.info( 'precision =  ' + repr( 1.0*len(dict_true_positive)/len(orderedVector)) )
		#logger.info(orderedVector)
		logger.info( 'unique artifacts in yield = ' + repr( len(set_artifact_in_yield) ) + ', ground truth artifacts in yield = ' + repr( len(set_artifact_in_yield_ground_truth) ) + ' (' + repr( 1.0*len(set_artifact_in_yield_ground_truth)/len(dict_artefact_cluster) ) + ' %)' )

		precision_scores_file.write( str(yield_value)+','+ str(nPrecision)+'\t' )

	precision_scores_file.write('\n')
	precision_scores_file.close()

if __name__ == "__main__":

	# make logger (global to STDOUT)
	LOG_FORMAT = ('%(levelname) -s %(asctime)s %(message)s')
	logger = logging.getLogger( __name__ )
	logging.basicConfig( level=logging.INFO, format=LOG_FORMAT )
	logger.info('logging started')

	Config = ConfigParser.ConfigParser()
	Config.read( "config.ini" )

	list_scores = read_file_with_distances( ConfigSectionReader(Config,"evaluation_app")['distances_file'],logger )
	artefacts_all=[]
	dict_artefact_cluster = read_artefacts_and_create_dict_with_clusters( ConfigSectionReader(Config,"all_app")['artefacts_file'] , ConfigSectionReader(Config,"all_app")['artefacts_file_with_clusters'], logger )
	logger.info( 'number of artifacts reported (no matches filtered) = ' + str(len(dict_artefact_cluster)) )



	Yield = ConfigSectionReader(Config,"evaluation_app")['yield'].rstrip('\n\r').split(",")
	compute_precision_at_yield( Yield, logger )


	logger.info( 'finished' )
